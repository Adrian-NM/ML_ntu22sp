{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlaRwNu7ojq"
      },
      "source": [
        "# **Homework 2 Phoneme Classification**\n",
        "\n",
        "* Slides: https://docs.google.com/presentation/d/1v6HkBWiJb8WNDcJ9_-2kwVstxUWml87b9CnA16Gdoio/edit?usp=sharing\n",
        "* Kaggle: https://www.kaggle.com/c/ml2022spring-hw2\n",
        "* Video: TBA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLQI0mNcmM-O",
        "outputId": "7d5b4d81-9438-4d50-8153-cd235c47ee21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Nov  3 23:54:51 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce RTX 4060 ...    Off | 00000000:01:00.0  On |                  N/A |\n",
            "| N/A   37C    P5               7W /  60W |   1061MiB /  8188MiB |     54%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      1199      G   /usr/lib/xorg/Xorg                           83MiB |\n",
            "|    0   N/A  N/A      1549      G   /usr/lib/xorg/Xorg                          386MiB |\n",
            "|    0   N/A  N/A      1699      G   /usr/bin/gnome-shell                        140MiB |\n",
            "|    0   N/A  N/A      3881      G   /usr/lib/firefox/firefox                    166MiB |\n",
            "|    0   N/A  N/A      4295      G   ...erProcess --variations-seed-version       57MiB |\n",
            "|    0   N/A  N/A      4569      G   ...gnu/webkit2gtk-4.0/WebKitWebProcess       47MiB |\n",
            "|    0   N/A  N/A      5299      G   ...erProcess --variations-seed-version      147MiB |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVUGfWTo7_Oj"
      },
      "source": [
        "## Download Data\n",
        "Download data from google drive, then unzip it.\n",
        "\n",
        "You should have\n",
        "- `libriphone/train_split.txt`\n",
        "- `libriphone/train_labels`\n",
        "- `libriphone/test_split.txt`\n",
        "- `libriphone/feat/train/*.pt`: training feature<br>\n",
        "- `libriphone/feat/test/*.pt`:  testing feature<br>\n",
        "\n",
        "after running the following block.\n",
        "\n",
        "> **Notes: if the links are dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2022spring-hw2/data) and upload it to the workspace, or you can use [the Kaggle API](https://www.kaggle.com/general/74235) to directly download the data into colab.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj5jYXsD9Ef3"
      },
      "source": [
        "### Download train/test metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzkiMEcC3Foq",
        "outputId": "cc90c16c-ee21-400e-ec08-dfcd422212a6"
      },
      "outputs": [],
      "source": [
        "# Main link\n",
        "# !wget -O libriphone.zip \"https://github.com/xraychen/shiny-robot/releases/download/v1.0/libriphone.zip\"\n",
        "\n",
        "# Backup Link 0\n",
        "# !pip install --upgrade gdown\n",
        "# !gdown --id '1o6Ag-G3qItSmYhTheX6DYiuyNzWyHyTc' --output libriphone.zip\n",
        "\n",
        "# Backup link 1\n",
        "# !pip install --upgrade gdown\n",
        "# !gdown --id '1R1uQYi4QpX0tBfUWt2mbZcncdBsJkxeW' --output libriphone.zip\n",
        "\n",
        "# Backup link 2\n",
        "# !wget -O libriphone.zip \"https://www.dropbox.com/s/wqww8c5dbrl2ka9/libriphone.zip?dl=1\"\n",
        "\n",
        "# Backup link 3\n",
        "# !wget -O libriphone.zip \"https://www.dropbox.com/s/p2ljbtb2bam13in/libriphone.zip?dl=1\"\n",
        "\n",
        "# !unzip -q libriphone.zip\n",
        "# !ls libriphone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_4anls8Drv"
      },
      "source": [
        "### Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po4N3C-AWuWl"
      },
      "source": [
        "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
        "\n",
        "A phoneme may span several frames and is dependent to past and future frames. \\\n",
        "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
        "\n",
        "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IJjLT8em-y9G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_feat(path):\n",
        "    feat = torch.load(path)\n",
        "    return feat\n",
        "\n",
        "def shift(x, n):\n",
        "    if n < 0:\n",
        "        left = x[0].repeat(-n, 1)\n",
        "        right = x[:n]\n",
        "\n",
        "    elif n > 0:\n",
        "        right = x[-1].repeat(n, 1)\n",
        "        left = x[n:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "    return torch.cat((left, right), dim=0)\n",
        "\n",
        "def concat_feat(x, concat_n):\n",
        "    assert concat_n % 2 == 1 # n must be odd\n",
        "    if concat_n < 2:\n",
        "        return x\n",
        "    seq_len, feature_dim = x.size(0), x.size(1)\n",
        "    x = x.repeat(1, concat_n) \n",
        "    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
        "    mid = (concat_n // 2)\n",
        "    for r_idx in range(1, mid+1):\n",
        "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
        "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
        "\n",
        "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
        "\n",
        "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, train_val_seed=1337):\n",
        "    class_num = 41 # NOTE: pre-computed, should not need change\n",
        "    mode = 'train' if (split == 'train' or split == 'val') else 'test'\n",
        "\n",
        "    label_dict = {}\n",
        "    if mode != 'test':\n",
        "      phone_file = open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines()\n",
        "\n",
        "      for line in phone_file:\n",
        "          line = line.strip('\\n').split(' ')\n",
        "          label_dict[line[0]] = [int(p) for p in line[1:]]\n",
        "\n",
        "    if split == 'train' or split == 'val':\n",
        "        # split training and validation data\n",
        "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
        "        random.seed(train_val_seed)\n",
        "        random.shuffle(usage_list)\n",
        "        percent = int(len(usage_list) * train_ratio)\n",
        "        usage_list = usage_list[:percent] if split == 'train' else usage_list[percent:]\n",
        "    elif split == 'test':\n",
        "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
        "    else:\n",
        "        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
        "\n",
        "    usage_list = [line.strip('\\n') for line in usage_list]\n",
        "    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
        "\n",
        "    max_len = 3000000\n",
        "    X = torch.empty(max_len, 39 * concat_nframes)\n",
        "    if mode != 'test':\n",
        "      y = torch.empty(max_len, dtype=torch.long)\n",
        "\n",
        "    idx = 0\n",
        "    for i, fname in tqdm(enumerate(usage_list)):\n",
        "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
        "        cur_len = len(feat)\n",
        "        feat = concat_feat(feat, concat_nframes)\n",
        "        if mode != 'test':\n",
        "          label = torch.LongTensor(label_dict[fname])\n",
        "\n",
        "        X[idx: idx + cur_len, :] = feat\n",
        "        if mode != 'test':\n",
        "          y[idx: idx + cur_len] = label\n",
        "\n",
        "        idx += cur_len\n",
        "\n",
        "    X = X[:idx, :]\n",
        "    if mode != 'test':\n",
        "      y = y[:idx]\n",
        "\n",
        "    print(f'[INFO] {split} set')\n",
        "    print(X.shape)\n",
        "    if mode != 'test':\n",
        "      print(y.shape)\n",
        "      return X, y\n",
        "    else:\n",
        "      return X\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5XW_x6udZQ"
      },
      "source": [
        "## Define Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fjf5EcmJtf4e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class LibriDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = X\n",
        "        if y is not None:\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqKNvNZwe3V"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bg-GRd7ywdrL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.BatchNorm1d(output_dim),\n",
        "            nn.Dropout(0.4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            BasicBlock(input_dim, hidden_dim),\n",
        "            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers-1)],\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlIq8JeqvvHC"
      },
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iIHn79Iav1ri"
      },
      "outputs": [],
      "source": [
        "# data prarameters\n",
        "concat_nframes = 19              # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
        "train_ratio = 0.8               # the ratio of data used for training, the rest will be used for validation\n",
        "\n",
        "# training parameters\n",
        "seed = 0                        # random seed\n",
        "batch_size = 2048                # batch size\n",
        "num_epoch = 50   \n",
        "early_stopping = 5               # the number of training epoch\n",
        "learning_rate = 0.0001           # learning rate\n",
        "model_path = './model.ckpt'     # the path where the checkpoint will be saved\n",
        "\n",
        "# model parameters\n",
        "input_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\n",
        "hidden_layers = 3               # the number of hidden layers\n",
        "hidden_dim = 1024                # the hidden dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIUFRgG5yoDn"
      },
      "source": [
        "## Prepare dataset and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1zI3v5jyrDn",
        "outputId": "3ea2823a-83f3-42d9-ef05-2f2c002f9538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset] - # phone classes: 41, number of utterances for train: 3428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]/tmp/ipykernel_111499/4129080341.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  feat = torch.load(path)\n",
            "3428it [00:04, 826.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] train set\n",
            "torch.Size([2116368, 741])\n",
            "torch.Size([2116368])\n",
            "[Dataset] - # phone classes: 41, number of utterances for val: 858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "858it [00:01, 826.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] val set\n",
            "torch.Size([527790, 741])\n",
            "torch.Size([527790])\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "# preprocess data\n",
        "train_X, train_y = preprocess_data(split='train', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
        "val_X, val_y = preprocess_data(split='val', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
        "\n",
        "# get dataset\n",
        "train_set = LibriDataset(train_X, train_y)\n",
        "val_set = LibriDataset(val_X, val_y)\n",
        "\n",
        "# remove raw feature to save memory\n",
        "del train_X, train_y, val_X, val_y\n",
        "gc.collect()\n",
        "\n",
        "# get dataloader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfRUEgC0GxUV",
        "outputId": "f9804711-72b1-4717-896b-821a300cfe87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'DEVICE: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "88xPiUnm0tAd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#fix seed\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  \n",
        "    np.random.seed(seed)  \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QTp3ZXg1yO9Y"
      },
      "outputs": [],
      "source": [
        "# fix random seed\n",
        "same_seeds(seed)\n",
        "\n",
        "# create model, define a loss function, and optimizer\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate*5, weight_decay=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=8, T_mult=2, eta_min=learning_rate*0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwWH1KIqzxEr"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdMWsBs7zzNs",
        "outputId": "17922ad2-a319-4253-8783-3e4939d0a7cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 26.02it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 53.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/050] Train Acc: 0.573859 Loss: 1.415735 | Val Acc: 0.645325 loss: 1.142657\n",
            "saving model with acc 0.645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 26.06it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 53.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[002/050] Train Acc: 0.626446 Loss: 1.207490 | Val Acc: 0.670342 loss: 1.055314\n",
            "saving model with acc 0.670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 26.26it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[003/050] Train Acc: 0.644719 Loss: 1.140899 | Val Acc: 0.681925 loss: 1.011973\n",
            "saving model with acc 0.682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:38<00:00, 26.56it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 53.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[004/050] Train Acc: 0.656911 Loss: 1.098083 | Val Acc: 0.693397 loss: 0.975133\n",
            "saving model with acc 0.693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 26.46it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[005/050] Train Acc: 0.666512 Loss: 1.064614 | Val Acc: 0.699263 loss: 0.952055\n",
            "saving model with acc 0.699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:38<00:00, 26.52it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[006/050] Train Acc: 0.674043 Loss: 1.038821 | Val Acc: 0.705735 loss: 0.931838\n",
            "saving model with acc 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:38<00:00, 26.54it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 51.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[007/050] Train Acc: 0.679853 Loss: 1.018844 | Val Acc: 0.710694 loss: 0.916307\n",
            "saving model with acc 0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:38<00:00, 26.93it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 57.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[008/050] Train Acc: 0.683993 Loss: 1.004806 | Val Acc: 0.712890 loss: 0.908074\n",
            "saving model with acc 0.713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:35<00:00, 29.54it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 57.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[009/050] Train Acc: 0.669736 Loss: 1.052503 | Val Acc: 0.703039 loss: 0.938981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:34<00:00, 30.08it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 58.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[010/050] Train Acc: 0.673153 Loss: 1.039668 | Val Acc: 0.707342 loss: 0.926623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:34<00:00, 29.91it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 59.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[011/050] Train Acc: 0.677062 Loss: 1.026420 | Val Acc: 0.710372 loss: 0.915918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:35<00:00, 29.44it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 58.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[012/050] Train Acc: 0.681089 Loss: 1.012799 | Val Acc: 0.713575 loss: 0.905243\n",
            "saving model with acc 0.714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:34<00:00, 30.01it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 58.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[013/050] Train Acc: 0.684587 Loss: 1.001104 | Val Acc: 0.716808 loss: 0.894883\n",
            "saving model with acc 0.717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:36<00:00, 28.64it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 58.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[014/050] Train Acc: 0.687670 Loss: 0.989230 | Val Acc: 0.719087 loss: 0.887079\n",
            "saving model with acc 0.719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:36<00:00, 27.97it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 54.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[015/050] Train Acc: 0.690805 Loss: 0.979283 | Val Acc: 0.722200 loss: 0.878643\n",
            "saving model with acc 0.722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:36<00:00, 28.25it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 59.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[016/050] Train Acc: 0.693775 Loss: 0.967609 | Val Acc: 0.723727 loss: 0.871530\n",
            "saving model with acc 0.724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:35<00:00, 28.82it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 57.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[017/050] Train Acc: 0.696772 Loss: 0.957740 | Val Acc: 0.726376 loss: 0.863284\n",
            "saving model with acc 0.726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 26.05it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 51.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[018/050] Train Acc: 0.699327 Loss: 0.949500 | Val Acc: 0.727833 loss: 0.857266\n",
            "saving model with acc 0.728\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 26.40it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[019/050] Train Acc: 0.701714 Loss: 0.941264 | Val Acc: 0.728943 loss: 0.853298\n",
            "saving model with acc 0.729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:38<00:00, 26.57it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[020/050] Train Acc: 0.703983 Loss: 0.932794 | Val Acc: 0.730154 loss: 0.847685\n",
            "saving model with acc 0.730\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 26.47it/s]\n",
            "100%|██████████| 258/258 [00:05<00:00, 51.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[021/050] Train Acc: 0.706285 Loss: 0.925749 | Val Acc: 0.732581 loss: 0.842867\n",
            "saving model with acc 0.733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:38<00:00, 26.68it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 51.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[022/050] Train Acc: 0.707832 Loss: 0.920438 | Val Acc: 0.733348 loss: 0.839352\n",
            "saving model with acc 0.733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:38<00:00, 26.64it/s]\n",
            "100%|██████████| 258/258 [00:05<00:00, 50.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[023/050] Train Acc: 0.708874 Loss: 0.916238 | Val Acc: 0.733870 loss: 0.837149\n",
            "saving model with acc 0.734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 25.98it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[024/050] Train Acc: 0.709503 Loss: 0.913037 | Val Acc: 0.734603 loss: 0.835271\n",
            "saving model with acc 0.735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.61it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[025/050] Train Acc: 0.695963 Loss: 0.960362 | Val Acc: 0.724635 loss: 0.866554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.35it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 51.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[026/050] Train Acc: 0.695213 Loss: 0.962568 | Val Acc: 0.725468 loss: 0.864635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.31it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 51.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[027/050] Train Acc: 0.696186 Loss: 0.958700 | Val Acc: 0.726177 loss: 0.862246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.63it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[028/050] Train Acc: 0.697191 Loss: 0.955038 | Val Acc: 0.727505 loss: 0.859718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.40it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[029/050] Train Acc: 0.698556 Loss: 0.952138 | Val Acc: 0.728873 loss: 0.855034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.64it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 53.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[030/050] Train Acc: 0.699430 Loss: 0.948103 | Val Acc: 0.729444 loss: 0.853588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 26.10it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[031/050] Train Acc: 0.701237 Loss: 0.942295 | Val Acc: 0.730741 loss: 0.849859\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:38<00:00, 26.92it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 51.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[032/050] Train Acc: 0.701862 Loss: 0.938589 | Val Acc: 0.731848 loss: 0.845560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:38<00:00, 26.66it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[033/050] Train Acc: 0.703157 Loss: 0.934779 | Val Acc: 0.732757 loss: 0.843164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:38<00:00, 26.74it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[034/050] Train Acc: 0.704723 Loss: 0.930345 | Val Acc: 0.733057 loss: 0.840780\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 25.96it/s]\n",
            "100%|██████████| 258/258 [00:05<00:00, 50.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[035/050] Train Acc: 0.705916 Loss: 0.925967 | Val Acc: 0.733640 loss: 0.838315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.57it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[036/050] Train Acc: 0.706684 Loss: 0.922807 | Val Acc: 0.734440 loss: 0.834842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.59it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[037/050] Train Acc: 0.708248 Loss: 0.918061 | Val Acc: 0.735467 loss: 0.832365\n",
            "saving model with acc 0.735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.44it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 51.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[038/050] Train Acc: 0.709375 Loss: 0.912813 | Val Acc: 0.736026 loss: 0.829334\n",
            "saving model with acc 0.736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:41<00:00, 24.89it/s]\n",
            "100%|██████████| 258/258 [00:05<00:00, 51.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[039/050] Train Acc: 0.710519 Loss: 0.910499 | Val Acc: 0.736501 loss: 0.828703\n",
            "saving model with acc 0.737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.36it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 51.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[040/050] Train Acc: 0.711676 Loss: 0.905932 | Val Acc: 0.738102 loss: 0.824552\n",
            "saving model with acc 0.738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 25.86it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[041/050] Train Acc: 0.712928 Loss: 0.901800 | Val Acc: 0.738398 loss: 0.822035\n",
            "saving model with acc 0.738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.45it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 53.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[042/050] Train Acc: 0.713923 Loss: 0.897579 | Val Acc: 0.739832 loss: 0.819821\n",
            "saving model with acc 0.740\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 25.95it/s]\n",
            "100%|██████████| 258/258 [00:05<00:00, 51.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[043/050] Train Acc: 0.714762 Loss: 0.894733 | Val Acc: 0.739967 loss: 0.817629\n",
            "saving model with acc 0.740\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 26.45it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 53.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[044/050] Train Acc: 0.716450 Loss: 0.890513 | Val Acc: 0.741166 loss: 0.815845\n",
            "saving model with acc 0.741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:38<00:00, 26.77it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 51.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[045/050] Train Acc: 0.717013 Loss: 0.887403 | Val Acc: 0.741492 loss: 0.812975\n",
            "saving model with acc 0.741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 26.37it/s]\n",
            "100%|██████████| 258/258 [00:05<00:00, 51.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[046/050] Train Acc: 0.718166 Loss: 0.883929 | Val Acc: 0.742049 loss: 0.810245\n",
            "saving model with acc 0.742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 26.11it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[047/050] Train Acc: 0.718820 Loss: 0.881742 | Val Acc: 0.742286 loss: 0.810100\n",
            "saving model with acc 0.742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:39<00:00, 26.06it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[048/050] Train Acc: 0.720041 Loss: 0.877891 | Val Acc: 0.743244 loss: 0.807999\n",
            "saving model with acc 0.743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.65it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 53.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[049/050] Train Acc: 0.720129 Loss: 0.876303 | Val Acc: 0.743618 loss: 0.806517\n",
            "saving model with acc 0.744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1034/1034 [00:40<00:00, 25.44it/s]\n",
            "100%|██████████| 258/258 [00:04<00:00, 52.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[050/050] Train Acc: 0.721488 Loss: 0.873240 | Val Acc: 0.744078 loss: 0.804609\n",
            "saving model with acc 0.744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "best_acc = 0.0\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    \n",
        "    # training\n",
        "    model.train() # set the model to training mode\n",
        "    for i, batch in enumerate(tqdm(train_loader)):\n",
        "        features, labels = batch\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad() \n",
        "        outputs = model(features) \n",
        "        \n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "        \n",
        "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
        "        train_loss += loss.item()\n",
        "    scheduler.step()\n",
        "    \n",
        "    # validation\n",
        "    if len(val_set) > 0:\n",
        "        model.eval() # set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(tqdm(val_loader)):\n",
        "                features, labels = batch\n",
        "                features = features.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(features)\n",
        "                \n",
        "                loss = criterion(outputs, labels) \n",
        "                \n",
        "                _, val_pred = torch.max(outputs, 1) \n",
        "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
        "                val_loss += loss.item()\n",
        "\n",
        "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
        "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
        "            ))\n",
        "\n",
        "            # if the model improves, save a checkpoint at this epoch\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
        "    else:\n",
        "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
        "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
        "        ))\n",
        "\n",
        "# if not validating, save the last epoch\n",
        "if len(val_set) == 0:\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print('saving model at last epoch')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab33MxosWLmG",
        "outputId": "911e8c9b-fc0f-4591-b0f6-311a1231c5e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "del train_loader, val_loader\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      },
      "source": [
        "## Testing\n",
        "Create a testing dataset, and load model from the saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOG1Ou0PGrhc",
        "outputId": "abaaa25b-a93c-49b0-d228-9eca1e2ab2e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset] - # phone classes: 41, number of utterances for test: 1078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]/tmp/ipykernel_111499/4129080341.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  feat = torch.load(path)\n",
            "1078it [00:02, 533.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] test set\n",
            "torch.Size([646268, 741])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "test_X = preprocess_data(split='test', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes)\n",
        "test_set = LibriDataset(test_X, None)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay0Fu8Ovkdad",
        "outputId": "e5b20aa7-4d8b-43a9-e068-f5c89706a360"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_111499/3352857437.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load model\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp-DV1p4r7Nz"
      },
      "source": [
        "Make prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84HU5GGjPqR0",
        "outputId": "cebd6694-8f74-44ff-f922-96ca4385acb8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 316/316 [00:04<00:00, 73.30it/s]\n"
          ]
        }
      ],
      "source": [
        "test_acc = 0.0\n",
        "test_lengths = 0\n",
        "pred = np.array([], dtype=np.int32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(tqdm(test_loader)):\n",
        "        features = batch\n",
        "        features = features.to(device)\n",
        "\n",
        "        outputs = model(features)\n",
        "\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyZqy40Prz0v"
      },
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GuljYSPHcZir"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
            "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
            "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
            "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
          ]
        }
      ],
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(pred):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ML2022Spring - HW2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
